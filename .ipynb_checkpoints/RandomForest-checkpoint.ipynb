{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Duplicate key in file PosixPath('/Users/akira/opt/anaconda3/envs/practice/lib/python3.7/site-packages/matplotlib/mpl-data/matplotlibrc'), line 250 ('font.family:  sans-serif')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import seaborn as sns\n",
    "# preprocessing：前処理  StandardScaler：標準化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# データを訓練データとテストデータに分割する\n",
    "from sklearn.model_selection import train_test_split\n",
    "# クラス分類をする\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "# 評価指標\n",
    "from sklearn.metrics import log_loss, accuracy_score, precision_recall_fscore_support, confusion_matrix, precision_score, recall_score, f1_score\n",
    "# 平均絶対誤差\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# 日時を扱う\n",
    "import datetime as dt\n",
    "# ロジスティック回帰\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# AUCとROC\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, mean_squared_error\n",
    "# ランダムフォレスト\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "kickstar = pd.read_csv('./data/ks-projects-201801 2.csv')\n",
    "\n",
    "# いらないカラムの削除\n",
    "kickstar = kickstar.drop(['ID', 'name', 'category'], axis=1)\n",
    "\n",
    "# 開始日と締め切りの差を期間として、periodという新しいカラムを作成\n",
    "kickstar['deadline'] = pd.to_datetime(kickstar['deadline'])\n",
    "kickstar['launched'] = pd.to_datetime(kickstar['launched'])\n",
    "kickstar['period'] = (kickstar['deadline'] - kickstar['launched']).dt.days\n",
    "kickstar =kickstar.drop(['deadline', 'launched'], axis=1)\n",
    "\n",
    "# ダミー変数の作成\n",
    "kickstar = pd.get_dummies(kickstar,columns=['main_category', 'currency', 'country'])\n",
    "\n",
    "# 欠損行削除\n",
    "kickstar = kickstar.dropna()\n",
    "\n",
    "# 目的変数を成功か失敗の２つに絞る\n",
    "kickstar = kickstar[(kickstar['state'] == 'successful') | (kickstar['state'] == 'failed')]\n",
    "\n",
    "# 説明変数と目的変数を用意\n",
    "y = kickstar['state'].values #'state' の値をyに代入する\n",
    "X = kickstar.drop('state', axis=1).values #'state'以外の変数をXに代入する\n",
    "\n",
    "# trainとtestに分割\n",
    "test_size = 0.2 #テストデータの割合を決める\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=0)\n",
    "#訓練データとテストデータに分割し、それぞれ変数に代入する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (265172, 59)\n",
      "X_test: (66293, 59)\n",
      "y_train: (265172,)\n",
      "y_test: (66293,)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train: {X_train.shape}')\n",
    "print(f'X_test: {X_test.shape}')\n",
    "print(f'y_train: {y_train.shape}')\n",
    "print(f'y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化\n",
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train) #訓練データの標準化\n",
    "X_test_std = stdsc.transform(X_test) #テストデータの標準化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ランダムフォレスト\n",
    "\n",
    "* 特徴量空間（説明変数となるデータがある空間）が線形分離可能な場合のみ高い性能を発揮します。\n",
    "\n",
    "アンサンブル学習のバギングをベースに、少しずつ異なる決定木をたくさん集めたもの。\n",
    "決定木単体の過学習しやすい欠点に対応。  \n",
    "それぞれ異なった方向に過学習している決定木をたくさん作れば、その結果の平均を取ることで過学習の度合いを減らすことができる。　　\n",
    "\n",
    "## 引数\n",
    "\n",
    "### n_estimators\n",
    "いくつの決定木を用意するかを設定。  \n",
    "大きいほど良いが、時間とメモリをくう。\n",
    "\n",
    "### max_features\n",
    "各グループの特徴量の個数。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# アンサンブル学習\n",
    "* 複数の機械学習モデルを組み合わせることで、より強力なモデルを構築するやり方。\n",
    "* 複数の学習器の多数決をとる。\n",
    "## バギング\n",
    "ブートストラップ(元データから一部のデータを復元抽出というやり方でサンプリング)というやり方で複数のモデルを並列的に学習。  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score= 0.9975563030787564\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=1234)\n",
    "model.fit(X_train_std, y_train)\n",
    "print(\"score=\", model.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestClassifier' object has no attribute 'coef_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b36d1bdff191>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"coefficient = {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"intercept = {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'coef_'"
     ]
    }
   ],
   "source": [
    "print(\"coefficient = {}\".format(model.coef_))\n",
    "print(\"intercept = {}\".format(model.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_std)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 性能評価\n",
    "* 混同行列（confusion matrix）\n",
    "* 正解率（accuracy）\n",
    "* 適合率（precision）\n",
    "* 再現率（recall）\n",
    "* F1スコア（F1-score）\n",
    "* AUC（曲線下面積）\n",
    "\n",
    "## 混同行列\n",
    "- TN(True Negative) : 実際にクラス0で正しくクラス0に分類されたデータ数（真陰性）  `\n",
    "- FP(False Positive) : 実際にはクラス0だが誤ってクラス1に分類されたデータ数(偽陽性)  \n",
    "- FN(False Positive) : 実際にはクラス1だが誤ってクラス0に分類されたデータ数(偽陰性)  \n",
    "- TP(True Positive) : 実際にクラス1で正しくクラス1に分類されたデータ数(真陽性)  \n",
    "「真・偽」は「分類が当たっているか」を表し、「陽性・陰性」は「クラス1・クラス0」を表します。  \n",
    "* `正解率` : 分類したデータの総数のうち、正しく分類されたデータ数の割合。 → (TP+TN)/(TP+FN+FP+TN)\n",
    "* `適合率` : クラス1に分類されたデータのうち、実際にクラス1であるデータ数の割合。 → TP/(TP+FP)\n",
    "* `再現率` : 実際にクラス1であるデータのうち、クラス1に分類されたデータ数の割合。 → TP/(TP+FN)\n",
    "* `F1スコア` : 適合率と再現率の調和平均。適合率と再現率はトレードオフの関係にあるため、F1スコアはこれらのバランスを評価するための指標と見ることができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('confusion matrix = \\n', confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "print('accuracy = {}'.format(accuracy_score(y_true=y_test, y_pred=y_pred)))\n",
    "print('precision = {}'.format(precision_score(y_true=y_test, y_pred=y_pred, pos_label=\"successful\")))\n",
    "print('recall = {}'.format(recall_score(y_true=y_test, y_pred=y_pred, pos_label=\"successful\")))\n",
    "print('f1 score = {}'.format(f1_score(y_true=y_test, y_pred=y_pred, pos_label=\"successful\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC\n",
    "ROC曲線の下側の面積部分。  \n",
    "値が大きいほど性能が良い。(最大値は１)  \n",
    "\n",
    "# ROC曲線\n",
    "横軸に偽陽性率（FPR: False Positive Rate）を、縦軸に真陽性率（TPR: True Positive Rate）をとった、モデルの分類性能を示した曲線。  \n",
    "閾値を調整して分類を調整。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = model.predict_proba(X_test_std)[:, 1] # 検証データがクラス1に属する確率\n",
    "fpr, tpr, thresholds = roc_curve(y_true=y_test, y_score=y_score, pos_label=\"successful\")\n",
    "\n",
    "plt.plot(fpr, tpr, label='roc curve (area = %0.3f)' % auc(fpr, tpr))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='random')\n",
    "plt.plot([0, 0, 1], [0, 1, 1], linestyle='--', label='ideal')\n",
    "plt.legend()\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('auc = ', roc_auc_score(y_true=y_test, y_score=y_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
